{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataset import *\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text:\n",
    "        t = '@user' if t == \"AT_USER\" else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 25711/25711 [00:00<00:00, 38730.03it/s] \n",
      "Found cached dataset json (/Users/pan/.cache/huggingface/datasets/json/default-904765d37cd2dbdc/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'created_at', 'user_id_str'],\n",
      "        num_rows: 106338\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_dir=\"./tweet\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alligment of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date prepared for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the encode and decode sequence: done\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "def tokenize_function(examples):\n",
    "    lower = [preprocess(x) for x in examples[\"text\"]]\n",
    "    result = tokenizer(lower)\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result\n",
    "result = tokenize_function(dataset[\"train\"][1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 9713, 3263, 1215, 47955, 4819, 9, 2350, 18, 3748, 5182, 4246, 68, 10, 102, 2911, 68, 885, 3892, 282, 68, 213, 2154, 68, 784, 571, 506, 721, 2050, 3964, 1258, 1735, 17066, 3923, 6031, 27586, 918, 111, 111, 33000, 2], [0, 405, 705, 40, 2501, 15162, 33000, 68, 10, 102, 2911, 15162, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'word_ids': [[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 11, 11, 12, 13, 13, 13, 14, 15, 15, 16, 17, 17, 17, 18, 18, 18, 18, 19, 20, 20, 20, 20, 20, 21, 22, 23, None], [None, 0, 0, 1, 2, 3, 4, 5, 6, 6, 6, 7, None]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>rt @user summary of yesterday's webcast featuring $ aapl $ wynn $ goog $ lgf tradereducation options hedgingstrategies - - URL</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': ['rt',\n",
       "  'AT_USER',\n",
       "  'summary',\n",
       "  'of',\n",
       "  \"yesterday's\",\n",
       "  'webcast',\n",
       "  'featuring',\n",
       "  '$',\n",
       "  'aapl',\n",
       "  '$',\n",
       "  'wynn',\n",
       "  '$',\n",
       "  'goog',\n",
       "  '$',\n",
       "  'lgf',\n",
       "  'tradereducation',\n",
       "  'options',\n",
       "  'hedgingstrategies',\n",
       "  '-',\n",
       "  '-',\n",
       "  'URL'],\n",
       " 'created_at': 'Wed Jan 01 03:29:29 +0000 2014',\n",
       " 'user_id_str': '1933063572'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenizer.decode(result[\"input_ids\"][0]))\n",
    "dataset[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
